{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aadd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT ANALYSIS ON X DATASET\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df5ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"X data.csv\"  # ensure file is in the same folder\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"✅ Dataset loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ File not found. Please check the file path or upload the dataset.\")\n",
    "\n",
    "print(\"\\nAvailable Columns:\", list(df.columns))\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "def clean_tweet(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", str(text))     # remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)             # remove mentions\n",
    "    text = re.sub(r\"#\", \"\", text)                 # remove hashtags\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)      # remove special chars\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Note: Data already has 'clean_text' column, so we'll use that directly\n",
    "# df['clean_text'] = df['text'].apply(clean_tweet)  # This line would cause KeyError\n",
    "\n",
    "# If you want to re-clean the text, uncomment below:\n",
    "# df['clean_text'] = df['clean_text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ae7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in clean_text\n",
    "print(f\"Missing values in clean_text before cleaning: {df['clean_text'].isna().sum()}\")\n",
    "\n",
    "# Option 1: Drop rows with missing text (recommended if you have enough data)\n",
    "df = df.dropna(subset=['clean_text'])\n",
    "\n",
    "# Option 2: Alternative - Fill with empty string (if you want to keep all rows)\n",
    "# df['clean_text'] = df['clean_text'].fillna('')\n",
    "\n",
    "print(f\"Missing values in clean_text after cleaning: {df['clean_text'].isna().sum()}\")\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "\n",
    "# Sentiment analysis functions\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_textblob_sentiment(text):\n",
    "    try:\n",
    "        # Handle empty strings and ensure we have valid text\n",
    "        if not isinstance(text, str) or text.strip() == '':\n",
    "            return 'Neutral'\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        if polarity > 0.1:\n",
    "            return 'Positive'\n",
    "        elif polarity < -0.1:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    except:\n",
    "        return 'Neutral'\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    try:\n",
    "        # Handle empty strings and ensure we have valid text\n",
    "        if not isinstance(text, str) or text.strip() == '':\n",
    "            return 'Neutral'\n",
    "\n",
    "        score = vader_analyzer.polarity_scores(text)['compound']\n",
    "        if score >= 0.05:\n",
    "            return 'Positive'\n",
    "        elif score <= -0.05:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    except:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to the cleaned text column\n",
    "df['textblob_sentiment'] = df['clean_text'].apply(get_textblob_sentiment)\n",
    "df['vader_sentiment'] = df['clean_text'].apply(get_vader_sentiment)\n",
    "\n",
    "print(\"\\n✅ Sentiment columns added successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth and model validation\n",
    "def convert_ground_truth(cat):\n",
    "    if cat == 1:\n",
    "        return 'Positive'\n",
    "    elif cat == -1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['ground_truth'] = df['category'].apply(convert_ground_truth)\n",
    "\n",
    "textblob_acc = (df['textblob_sentiment'] == df['ground_truth']).mean()\n",
    "vader_acc = (df['vader_sentiment'] == df['ground_truth']).mean()\n",
    "\n",
    "print(f\"\\n📊 TextBlob Accuracy: {textblob_acc*100:.2f}%\")\n",
    "print(f\"📊 VADER Accuracy: {vader_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032504ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='ground_truth', data=df, order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title(\"Ground Truth Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='textblob_sentiment', data=df, order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title(\"TextBlob Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='vader_sentiment', data=df, order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title(\"VADER Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm_vader = confusion_matrix(df['ground_truth'], df['vader_sentiment'], labels=['Positive','Neutral','Negative'])\n",
    "ConfusionMatrixDisplay(cm_vader, display_labels=['Positive','Neutral','Negative']).plot(cmap='Blues')\n",
    "plt.title(\"VADER Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
